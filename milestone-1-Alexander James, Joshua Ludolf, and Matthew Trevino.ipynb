{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1 - NFStream Code Walkthrough \n",
    "## Name: Alexander James, Joshua Ludolf, & Matthew Trevino\n",
    "``Date: 02-25-2025``\n",
    "### Description of this file:\n",
    "This Jupyter Notebook provides a comprehensive walkthrough of using the `nfstream` library for network traffic analysis. The notebook includes the following sections:\n",
    "\n",
    "1. **Installation of Requirements**: Installing the necessary `nfstream` library.\n",
    "2. **Importing Libraries**: Importing the required libraries for network traffic analysis.\n",
    "3. **Library Information**: Detailed information about the `nfstream` library and its key features.\n",
    "4. **Main Function**: Defining and executing the main function to read a pcap file, analyze the network flows, and convert the flows into a pandas DataFrame for further analysis and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Installing Requirements\n",
    "%pip install nfstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from nfstream import NFStreamer, NFPlugin\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Information about the nfstream Library\n",
    "\n",
    "The `nfstream` library is a Python package designed for network traffic analysis. It provides a high-level interface to capture, analyze, and process network flows from pcap files or live network interfaces. The library is built on top of the nDPI (ntop Deep Packet Inspection) library, which allows it to perform deep packet inspection and extract detailed information from network traffic.\n",
    "\n",
    "### Key Features:\n",
    "- **Flow-based Analysis**: Extracts and processes network flows, which are sequences of packets sharing common attributes such as source and destination IP addresses, ports, and protocols.\n",
    "- **Deep Packet Inspection**: Uses nDPI to classify traffic and extract metadata from packets, including application protocols, SSL/TLS information, and more.\n",
    "- **Customizable**: Allows users to define custom BPF (Berkeley Packet Filter) filters, set snapshot lengths, and configure various timeout settings for flow analysis.\n",
    "- **Integration with Pandas**: Converts network flows into Pandas DataFrames for easy manipulation, analysis, and visualization.\n",
    "- **Performance Reporting**: Provides performance metrics and reports for the analyzed traffic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the main function\n",
    "def main():\n",
    "    pcap_file = os.path.join(os.getcwd(), \"demo.pcap\")\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(pcap_file):\n",
    "        raise FileNotFoundError(f\"The file {pcap_file} does not exist.\")\n",
    "\n",
    "    # Create a NFStreamer object to analyze pcap file and extract flows\n",
    "\n",
    "    my_streamer = NFStreamer(source=pcap_file,\n",
    "                             decode_tunnels=True,\n",
    "                             bpf_filter=None,\n",
    "                             promiscuous_mode=True,\n",
    "                             snapshot_length=1093,\n",
    "                             idle_timeout=120,\n",
    "                             active_timeout=1800,\n",
    "                             accounting_mode=0,\n",
    "                             udps=None,\n",
    "                             n_dissections=20,\n",
    "                             statistical_analysis=False,\n",
    "                             splt_analysis=0,\n",
    "                             n_meters=0,\n",
    "                             max_nflows=0,\n",
    "                             performance_report=0,\n",
    "                             system_visibility_mode=0,\n",
    "                             system_visibility_poll_ms=100)\n",
    "    \n",
    "\n",
    "    my_dataframe = my_streamer.to_pandas(columns_to_anonymize=[]).set_index('id') # convert the flows to a pandas dataframe and set 'id' as the index column\n",
    "    print(f\"\\n{my_dataframe}\") # print the dataframe\n",
    "    \n",
    "    total_flows_count = my_streamer.to_csv(path=None, columns_to_anonymize=[], flows_per_file=0, rotate_files=0) # convert the flows to a csv file\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
